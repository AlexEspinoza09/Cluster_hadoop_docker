# Resultado de la Demostraci√≥n del Cluster Hadoop

## ‚úÖ Prueba Completada Exitosamente

Acabas de ejecutar un trabajo de **MapReduce WordCount** que proces√≥ 100,000 l√≠neas de texto distribuido entre tus 3 nodos.

## üìä M√©tricas de Rendimiento

### Tiempo de Ejecuci√≥n
- **Fase Map**: 19.2 segundos
- **Fase Reduce**: 9.2 segundos
- **Total**: ~28 segundos

### Procesamiento de Datos
- **L√≠neas procesadas**: 100,000
- **Datos le√≠dos desde HDFS**: 6.2 MB
- **Datos escritos**: 833 bytes
- **Palabras √∫nicas encontradas**: 60

### Uso de Recursos
- **CPU total**: 13.1 segundos
- **Memoria pico**: ~551 MB
- **Nodos participantes**: 3 (hadoop-master, hadoop-worker1, hadoop-worker2)

## üèÜ Top 15 Palabras M√°s Frecuentes

| Palabra | Frecuencia |
|---------|-----------|
| de | 50,000 |
| datos | 40,000 |
| procesamiento | 30,000 |
| nodos | 30,000 |
| los | 30,000 |
| entre | 30,000 |
| en | 30,000 |
| tareas | 20,000 |
| paralelo | 20,000 |
| para | 20,000 |
| la | 20,000 |
| el | 20,000 |
| del | 20,000 |
| cluster | 20,000 |
| Los | 20,000 |

## üåê Ver Resultados en las Interfaces Web

### 1. ResourceManager - Ver el Job Ejecutado
**URL**: http://localhost:8088/cluster/apps

Aqu√≠ puedes ver:
- Lista de todas las aplicaciones ejecutadas
- Click en "word count" para ver detalles del job
- M√©tricas de tiempo, memoria y CPU
- Distribuci√≥n del trabajo entre nodos

### 2. Job History - M√©tricas Detalladas
**URL**: http://localhost:19888/jobhistory

Ver√°s:
- Historial completo del job
- Detalles de cada tarea Map y Reduce
- Gr√°ficos de rendimiento
- Logs de ejecuci√≥n

### 3. NameNode - Explorar Archivos HDFS
**URL**: http://localhost:9870/explorer.html#/demo

Puedes:
- Navegar por el sistema de archivos HDFS
- Ver el archivo de entrada: `/demo/input/bigdataset.txt`
- Ver los resultados: `/demo/output/part-r-00000`
- Descargar archivos

## üîç C√≥mo Funciona el Procesamiento Distribuido

### Paso 1: Divisi√≥n de Datos (Map Phase)
```
Archivo grande (6.2 MB, 100,000 l√≠neas)
         ‚Üì
    Dividido en bloques
         ‚Üì
  Procesado en paralelo por los 3 nodos
         ‚Üì
    Cada nodo cuenta palabras localmente
```

### Paso 2: Agregaci√≥n (Shuffle & Sort)
```
Resultados de cada nodo
         ‚Üì
    Transferidos y ordenados
         ‚Üì
    Agrupados por palabra
```

### Paso 3: Reducci√≥n (Reduce Phase)
```
Palabras agrupadas
         ‚Üì
    Conteo final por palabra
         ‚Üì
    Resultado: 60 palabras √∫nicas con sus frecuencias
```

## üéØ Lo Que Demuestra Esta Prueba

1. **Comunicaci√≥n entre Nodos**: Los 3 nodos (master + 2 workers) se comunicaron exitosamente
2. **Procesamiento Paralelo**: Las tareas Map se distribuyeron entre los nodos disponibles
3. **HDFS Funcional**: Los datos se almacenaron y leyeron correctamente
4. **YARN Operativo**: ResourceManager coordin√≥ la ejecuci√≥n exitosamente
5. **MapReduce Completo**: Todo el ciclo Map-Shuffle-Reduce funcion√≥ correctamente

## üöÄ Pr√≥ximas Pruebas Sugeridas

### Prueba 1: Estimaci√≥n de Pi (CPU Intensivo)
```bash
docker exec -u hadoop hadoop-master hadoop jar \
  /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
  pi 20 10000
```
**Qu√© hace**: Usa el m√©todo Monte Carlo para estimar Pi. Ver√°s c√≥mo se distribuye el c√°lculo intensivo.

### Prueba 2: Benchmark de Lectura/Escritura (I/O)
```bash
# Escritura
docker exec -u hadoop hadoop-master hadoop jar \
  /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar \
  TestDFSIO -write -nrFiles 10 -fileSize 100MB

# Lectura
docker exec -u hadoop hadoop-master hadoop jar \
  /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar \
  TestDFSIO -read -nrFiles 10 -fileSize 100MB
```
**Qu√© hace**: Mide el rendimiento de I/O del cluster (MB/s).

### Prueba 3: TeraSort (Ordenamiento Masivo)
```bash
# Generar datos
docker exec -u hadoop hadoop-master hadoop jar \
  /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
  teragen 1000000 /terasort-input

# Ordenar
docker exec -u hadoop hadoop-master hadoop jar \
  /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
  terasort /terasort-input /terasort-output

# Validar
docker exec -u hadoop hadoop-master hadoop jar \
  /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
  teravalidate /terasort-output /terasort-validate
```
**Qu√© hace**: Benchmark est√°ndar de Hadoop para medir rendimiento de ordenamiento.

## üìà C√≥mo Interpretar los Resultados

### En ResourceManager (http://localhost:8088):
- **State: FINISHED** = Job completado exitosamente
- **Final Status: SUCCEEDED** = Sin errores
- **Progress: 100%** = Todo procesado
- **Elapsed Time** = Duraci√≥n total del job

### En Job History (http://localhost:19888):
- **Map Tasks** = N√∫mero de tareas de procesamiento paralelo
- **Reduce Tasks** = N√∫mero de tareas de agregaci√≥n
- **CPU Time** = Tiempo real de procesamiento
- **Shuffle Time** = Tiempo de transferencia de datos entre nodos

## üí° Tips para Mejorar el Rendimiento

1. **M√°s datos = mejor paralelismo**: Archivos peque√±os no se benefician mucho del paralelismo
2. **Ajustar memoria**: Si los jobs fallan, aumenta la memoria en `yarn-site.xml`
3. **Balanceo de carga**: YARN distribuye autom√°ticamente el trabajo
4. **Monitoreo**: Usa las interfaces web para identificar cuellos de botella

## üìù Archivos Creados

Los resultados est√°n en HDFS:
```bash
# Ver resultados
docker exec -u hadoop hadoop-master hdfs dfs -cat /demo/output/part-r-00000

# Listar archivos
docker exec -u hadoop hadoop-master hdfs dfs -ls -R /demo

# Descargar resultados
docker exec -u hadoop hadoop-master hdfs dfs -get /demo/output/part-r-00000 /tmp/resultado.txt
```

## üéì Aprendizajes Clave

1. **HDFS**: Almacena datos de forma distribuida y confiable
2. **YARN**: Gestiona recursos y coordina ejecuci√≥n
3. **MapReduce**: Procesa datos en paralelo de forma eficiente
4. **Comunicaci√≥n**: Los nodos se coordinan autom√°ticamente
5. **Escalabilidad**: A√±adir m√°s nodos mejorar√≠a el rendimiento

---

**¬°Tu cluster Hadoop est√° funcionando perfectamente!** üéâ

Puedes ejecutar m√°s pruebas o desarrollar tus propias aplicaciones MapReduce.
